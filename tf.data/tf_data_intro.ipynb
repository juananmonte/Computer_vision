{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro: how to use tf.data and how to compare it to other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.data import AUTOTUNE\n",
    "import tensorflow as tf\n",
    "#others\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a function to benchmark time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(datasetGen, numSteps):\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(0, numSteps):\n",
    "        (images, labels) = next(datasetGen) #Use the \"next\" function from python to get each batch of data\n",
    "    \n",
    "    end = time.time()\n",
    "    return(end-start) #Difference between the time it started and the above loop finishes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 28s 0us/step\n"
     ]
    }
   ],
   "source": [
    "BS = 64\n",
    "NUM_STEPS = 5000\n",
    "((trainX, trainY), (testX, testY)) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Program ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageGen = ImageDataGenerator() #initialize it\n",
    "dataGen = imageGen.flow(x=trainX, y=trainY, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Program tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((trainX, trainY))\n",
    "dataset = (dataset.shuffle(1024).cache().repeat().batch(BS).prefetch(AUTOTUNE))\n",
    "datasetGen = iter(dataset) #create a dataset iterator that goes trough the time function\n",
    "\n",
    "#.shuffle: Builds a buffer of 1024 elements from the dataset and shuffles it.\n",
    "#.cache(): Caches the result. This makes subsequent data reads/accesses faster.\n",
    "#.repeat(): loops through batches of data.\n",
    "#.prefetch(): Builds batches of data behind the scenes. Improves through/put rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaluate the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time tf method: 320000 10.27061939239502\n"
     ]
    }
   ],
   "source": [
    "totalTime_idg = benchmark(dataGen, NUM_STEPS)\n",
    "print(\"total time tf method:\", BS*NUM_STEPS, totalTime_idg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time tf method: 320000 1.52409029006958\n"
     ]
    }
   ],
   "source": [
    "totalTime_tf = benchmark(datasetGen, NUM_STEPS)\n",
    "print(\"total time tf method:\", BS*NUM_STEPS, totalTime_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### So, tf.data() takes 1.52409029006958 seconds to go through all data. This is 6.7 times faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But, how do we use tf.data() when the data is on disk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'broccoli', 'grape', 'lemon', 'mango', 'orange',\n",
       "       'strawberry'], dtype='<U10')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sorted(os.listdir(\"G:/pyimage_univ/CNN_tf/tf.data/fruits\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the information\n",
    "imagePaths = list(paths.list_images(\"G:/pyimage_univ/CNN_tf/tf.data/fruits\"))#goes through all folders and looks for images\n",
    "classNames = np.array(sorted(os.listdir(\"G:/pyimage_univ/CNN_tf/tf.data/fruits\"))) #get all folders names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to load the data and pre-process it usinf tf\n",
    "def load_images(imagePath):\n",
    "    #--images\n",
    "    image = tf.io.read_file(imagePath) #read the data\n",
    "    image = tf.image.decode_png(image, channels=3) #it can also decode jpeg, gif, bmp...\n",
    "    image = tf.image.resize(image, (96,96))/ 255.0 #don't forget to rescale the pixels\n",
    "    #--labels\n",
    "    label = tf.strings.split(imagePath, os.path.sep)[-2]#the name of the folder \n",
    "    oneHot = label == classNames #see if the obtained labels match with the classes names we got before\n",
    "    encodedLabel = tf.argmax(oneHot)#get the highest value\n",
    "\n",
    "    return(image, encodedLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.string>\n",
      "<PrefetchDataset shapes: ((None, 96, 96, 3), (None,)), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(imagePaths)\n",
    "print(dataset)\n",
    "dataset = (dataset.shuffle(1024).map(load_images, num_parallel_calls=AUTOTUNE).cache().repeat().\n",
    "            batch(BS).prefetch(AUTOTUNE))\n",
    "print(dataset)\n",
    "#map works like the normal map function of python. Every image will go through the load_images function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating a ImageDataGenerator object...\n",
      "Found 6688 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "### Compare to ImageDataGenerator\n",
    "print(\"[INFO] creating a ImageDataGenerator object...\")\n",
    "imageGen = ImageDataGenerator(rescale=1.0/255)\n",
    "dataGen = imageGen.flow_from_directory(\n",
    "\t\"G:/pyimage_univ/CNN_tf/tf.data/fruits\",\n",
    "\ttarget_size=(96, 96),\n",
    "\tbatch_size=BS,\n",
    "\tclass_mode=\"categorical\",\n",
    "\tcolor_mode=\"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTime = benchmark(dataGen, NUM_STEPS)\n",
    "print(\"idg\", BS * NUM_STEPS, totalTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] tf.data generated 320000 images in 35.85 seconds...\n"
     ]
    }
   ],
   "source": [
    "datasetGen = iter(dataset)\n",
    "totalTime = benchmark(datasetGen, NUM_STEPS)\n",
    "print(\"tf.data()\", BS * NUM_STEPS, totalTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('gpu-dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "244139a3b14db007857c14f2a9d5e3b23ed735eeb2f38a787fb45edaaccb434b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
