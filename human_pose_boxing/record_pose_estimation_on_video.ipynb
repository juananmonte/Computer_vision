{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code is to map pose estimation and save it on a video for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(0)\n",
    "# url = \"rtsp://quebuennombre:1234cameraparacv2@192.168.45.19:554/stream1\"\n",
    "# cap = VideoStream(url).start()\n",
    "#cap = FileVideoStream(\"G:\\\\box_app\\\\punches_1.mp4\").start() #faster\n",
    "\n",
    "cap = cv2.VideoCapture(\"G:\\\\box_app\\\\basic_punches_2.mp4\")\n",
    "time.sleep(2.0)\n",
    "\n",
    "width = int(cap.get(3))\n",
    "height = int(cap.get(4))\n",
    "frame_size = (width, height)\n",
    "fps = 10\n",
    "\n",
    "output = cv2.VideoWriter(\"G:\\\\box_app\\\\test9.mp4\", cv2.VideoWriter_fourcc(*'XVID'), fps, frame_size)\n",
    "\n",
    "#Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while True: #cap.isOpened():\n",
    "        ret, frame = cap.read()#ret, frame = cap.read()\n",
    "        # frame = resize(frame,width=450)\n",
    "        # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # frame = np.dstack([frame, frame, frame]) #to make the image 3Dso to pass it later to BGR\n",
    "        \n",
    "        if ret == True:\n",
    "        #Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "                \n",
    "            #Make detection\n",
    "            results = pose.process(image)\n",
    "                \n",
    "            #REcolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "            #Extract landmarks\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            #Render detections\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                        mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                        mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "            output.write(image)\n",
    "\n",
    "            #Show the image\n",
    "            cv2.imshow(\"Mediapipe feed\", image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
