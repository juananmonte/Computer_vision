{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defending from Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the easiest ways to defend against adversarial attacks is to train your model on these types of images.\n",
    "\n",
    "For example, if we are worried nefarious users applying FGSM attacks to our model, then we can “inoculate” our neural network by training them on FSGM images of our own.\n",
    "\n",
    "Typically, this type of adversarial inoculation is applied by either:\n",
    "\n",
    "1. Training our model on a given dataset, generating a set of adversarial images, and then fine-tuning the model on the adversarial images\n",
    "2. Generating mixed batches of both the original training images and adversarial images, followed by fine-tuning our neural network on these mixed batches\n",
    "\n",
    "**The first method is simpler and requires less computation** (since we need to generate only one set of adversarial images). **The downside is that this method tends to be less robust** since we’re only fine-tuning the model on adversarial examples at the end of training.\n",
    "\n",
    "**The second method is much more complicated and requires significantly more computation**. We need to use the model to generate adversarial images for each batch where the network is trained.\n",
    "**The benefit is that the model tends to be more robust because it sees both original training images and adversarial images during every single batch update during training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Utilities\n",
    "from pyimagesearch.simplecnn import SimpleCNN \n",
    "from pyimagesearch.datagen import generate_adversarial_batch\n",
    "#---Tensorflow\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "#---Others\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "trainX = trainX/255.0\n",
    "testX = testX/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = to_categorical(trainY,10)\n",
    "testY = to_categorical(testY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss='categorical_crossentropy', optimizer = Adam(learning_rate=1e-3), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 17:33:03.138900: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-09-25 17:33:04.424764: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-09-25 17:33:04.425816: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-09-25 17:33:04.425858: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-09-25 17:33:04.426479: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-09-25 17:33:04.426594: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 11s 8ms/step - loss: 0.1982 - accuracy: 0.9411 - val_loss: 0.0705 - val_accuracy: 0.9775\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0801 - accuracy: 0.9754 - val_loss: 0.0515 - val_accuracy: 0.9825\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0591 - accuracy: 0.9821 - val_loss: 0.0391 - val_accuracy: 0.9863\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0482 - accuracy: 0.9843 - val_loss: 0.0484 - val_accuracy: 0.9827\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 0.0577 - val_accuracy: 0.9816\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0336 - accuracy: 0.9891 - val_loss: 0.0458 - val_accuracy: 0.9853\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.0411 - val_accuracy: 0.9868\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0254 - accuracy: 0.9919 - val_loss: 0.0392 - val_accuracy: 0.9874\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0416 - val_accuracy: 0.9866\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.0378 - val_accuracy: 0.9887\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0397 - val_accuracy: 0.9886\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0486 - val_accuracy: 0.9866\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0411 - val_accuracy: 0.9886\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.0549 - val_accuracy: 0.9853\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0405 - val_accuracy: 0.9899\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0402 - val_accuracy: 0.9888\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.0429 - val_accuracy: 0.9885\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0455 - val_accuracy: 0.9882\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.0456 - val_accuracy: 0.9881\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0420 - val_accuracy: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89cc0f0160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, validation_data=(testX, testY),batch_size=64, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loss: 0.0420, \n",
      "acc: 0.9903\n"
     ]
    }
   ],
   "source": [
    "#make predictions on the test set and get the loss and accuracy\n",
    "\n",
    "(loss, acc) = model.evaluate(testX, testY, verbose=0)\n",
    "print(\"[INFO] loss: {:.4f}, \\nacc: {:.4f}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the adversarial set from the test set. Create len(test) number of images\n",
    "(advX, advY) = next(generate_adversarial_batch(model, len(testX), testX, testY, (28,28,1), eps=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loss: 17.8904, \n",
      "acc: 0.0230\n"
     ]
    }
   ],
   "source": [
    "#re-evaluate the model on the adversarial images\n",
    "(loss, acc) = model.evaluate(x=advX, y=advY, verbose=0)\n",
    "print(\"[INFO] loss: {:.4f}, \\nacc: {:.4f}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/gpu-dl/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# lower the learning rate and re-traiin the model on the adversarial images\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=1e-4), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 2s 7ms/step - loss: 8.9580 - accuracy: 0.1927\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.7033 - accuracy: 0.6186\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.0879 - accuracy: 0.8082\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6008 - accuracy: 0.8805\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3840 - accuracy: 0.9172\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2542 - accuracy: 0.9420\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1865 - accuracy: 0.9563\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1534 - accuracy: 0.9626\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1138 - accuracy: 0.9715\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0949 - accuracy: 0.9744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89c439faf0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(advX, advY, batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " normal testing images *after* fine-tuning:\n",
      "loss: 0.0480, \n",
      "acc: 0.9865\n"
     ]
    }
   ],
   "source": [
    "#evaluate it on the test set (i.e., non-adversarial) again to see if performance has degraded\n",
    "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
    "print(\" normal testing images *after* fine-tuning:\")\n",
    "print(\"loss: {:.4f}, \\nacc: {:.4f}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversarial images *after* fine-tuning:\n",
      "loss: 0.0474, \n",
      "acc: 0.9858\n"
     ]
    }
   ],
   "source": [
    "# do a final evaluation of the model on the adversarial images\n",
    "(loss, acc) = model.evaluate(x=advX, y=advY, verbose=0)\n",
    "print(\"adversarial images *after* fine-tuning:\")\n",
    "print(\"loss: {:.4f}, \\nacc: {:.4f}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gpu-dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da695c087d6368c9b262a08c2ebf368542a47f83b2881693eefdf5ebab9d0ecb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
