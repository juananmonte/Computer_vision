{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Haar Cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV’s Haar cascade face detector is the original face detector that shipped with the library. It’s also the face detector that is familiar to almost everyone.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "- Very fast, capable of running in super real-time\n",
    "- Low computational requirements — can easily be run on embedded, resource-constrained devices such as the Raspberry Pi (RPi), NVIDIA Jetson Nano, and Google Coral\n",
    "- Small model size (just over 400KB; for reference, most deep neural networks will be anywhere between 20-200MB).\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "- Highly prone to false-positive detections\n",
    "- Typically requires manual tuning to the detectMultiScale function\n",
    "- Not anywhere near as accurate as its HOG + Linear SVM and deep learning-based face detection counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model\n",
    "#Remember to use the full path\n",
    "detector = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the image, resizezz it and recolor it\n",
    "image = cv2.imread('./messi.png')\n",
    "image = imutils.resize(image, width=500)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a look at what each of these arguments means:\n",
    "\n",
    "**scaleFactor:** \n",
    "\n",
    "How much the image size is reduced at each image scale. This value is used to create the scale pyramid. To detect faces at multiple scales in the image (some faces may be closer to the foreground, and thus be larger, other faces may be smaller and in the background, thus the usage of varying scales). **A value of 1.05 indicates that we are reducing the size of the image by 5% at each level in the pyramid.**\n",
    "\n",
    "\n",
    "**minNeighbors:** \n",
    "\n",
    "How many neighbors each window should have for the area in the window to be considered a face. The cascade classifier will detect multiple windows around a face. **This parameter controls how many rectangles (neighbors) need to be detected for the window to be labeled a face.**\n",
    "\n",
    "\n",
    "**minSize:** \n",
    "\n",
    "A tuple of width and height (in pixels) **indicating the window’s minimum size**. **Bounding boxes smaller than this size are ignored.** It is a good idea to start with (30, 30) and fine-tune from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the model\n",
    "rects = detector.detectMultiScale(gray, scaleFactor=1.05,\n",
    "\t            minNeighbors=5, minSize=(30, 30),\n",
    "\t            flags=cv2.CASCADE_SCALE_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the coordinates of the bounding box and draw it\n",
    "for (x, y, w, h) in rects:\n",
    "    cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VideoStream(0).start()\n",
    "time.sleep(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    frame  = vs.read()\n",
    "    frame = imutils.resize(frame, width=500)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t# perform face detection\n",
    "    rects = detector.detectMultiScale(gray, scaleFactor=1.05,\n",
    "    minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "\t# loop over the bounding boxes\n",
    "    for (x, y, w, h) in rects:\n",
    "\t\t# draw the face bounding box on the image\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\t# show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV2 DNN face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV’s deep learning face detector is based on a Single Shot Detector (SSD) with a small ResNet backbone, allowing it to be both accurate and fast.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "- Accurate face detector\n",
    "- Utilizes modern deep learning algorithms\n",
    "- No parameter tuning required\n",
    "- Can run in real-time on modern laptops and desktops\n",
    "- Model is reasonably sized (just over 10MB)\n",
    "- Relies on OpenCV’s cv2.dnn module\n",
    "- Can be made faster on embedded devices by using OpenVINO and the Movidius NCS\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "- More accurate than Haar cascades and HOG + Linear SVM, but not as accurate as dlib’s CNN MMOD face detector\n",
    "- May have unconscious biases in the training set — may not detect darker-skinned people as accurately as lighter-skinned people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model\n",
    "#We need to point the path to a prototxt and caffe model files\n",
    "net = cv2.dnn.readNetFromCaffe('./res10_300x300_ssd_iter_140000.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dnn.blobFromImage takes care of pre-processing which includes setting the blob dimensions and normalization.\n",
    "image = cv2.imread('./iron_chic.jpg')\n",
    "(h,w) = image.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(image, (300,300)), 1.0, (300,300), (104.0, 177.0,123.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass the blob through the network and obtain the detections and predictions\n",
    "net.setInput(blob)\n",
    "detections = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over the obtained detections and draw them\n",
    "for i in range(0, detections.shape[2]):\n",
    "    #extract the coordinates where the confidence (probability) associated with the prediction\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "\n",
    "    if confidence > 0.5: #set threshold\n",
    "        #compute the x, y coordinates if the bounding box\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "        #Draw the bounding box\n",
    "        text = '{:.2f}'.format(confidence*100)\n",
    "        #set the value of y to locate the text on the rectangle\n",
    "        y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "        cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,0.255), 2)\n",
    "    \n",
    "    cv2.imshow(\"output\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DLIB HOG + Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Haar cascades, HOG + Linear SVM relies on image pyramids and sliding windows to detect objects/faces in an image.\n",
    "\n",
    "The algorithm is a classic in computer vision literature and is still used today.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "- More accurate than Haar cascades\n",
    "- More stable detection than Haar cascades (i.e., fewer parameters to tune)\n",
    "- Extremely well documented, both in terms of the dlib implementation and the HOG + Linear SVM framework in the computer vision literature\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "- Only works on frontal views of the face — profile faces will not be detected as the HOG descriptor does not tolerate changes in rotation or viewing angle well\n",
    "- Requires an additional library (dlib) be installed — not necessarily a problem per se, but if you’re using just OpenCV, then you may find adding another library into the mix cumbersome\n",
    "- Not as accurate as deep learning-based face detectors\n",
    "- For the accuracy, it’s actually quite computationally expensive due to image pyramid construction, sliding windows, and computing HOG features at every stop of the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First is necessary to define a helper function: convert the resulting dlib rectangle objects to bounding boxes,\n",
    "# then ensure the bounding boxes are all within the bounds of the\n",
    "# input image\n",
    "\n",
    "def convert_and_trim_bb(image, rect):\n",
    "\t# extract the starting and ending (x, y)-coordinates of the bounding box\n",
    "\tstartX = rect.left()\n",
    "\tstartY = rect.top()\n",
    "\tendX = rect.right()\n",
    "\tendY = rect.bottom()\n",
    "\n",
    "\t# ensure the bounding box coordinates fall within the spatial dimensions of the image\n",
    "\tstartX = max(0, startX)\n",
    "\tstartY = max(0, startY)\n",
    "\tendX = min(endX, image.shape[1])\n",
    "\tendY = min(endY, image.shape[0])\n",
    "\n",
    "\t# compute the width and height of the bounding box\n",
    "\tw = endX - startX\n",
    "\th = endY - startY\n",
    "\n",
    "\t# return our bounding box coordinates\n",
    "\treturn (startX, startY, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the detector\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read, resize and recolor the image\n",
    "image = cv2.imread('./images/concert.jpg')\n",
    "image = imutils.resize(image, width=600)\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform face detection\n",
    "rects = detector(rgb, 1 ) # 1 is the number of times to upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain the boxes coordinates from the face detection\n",
    "boxes = [convert_and_trim_bb(image, r) for r in rects]\n",
    "\n",
    "#Draw the bb on the image\n",
    "for (x, y, w, h) in boxes:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dlib’s CNN face detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Davis King, the creator of dlib, trained a CNN face detector based on his work on max-margin object detection. The method is highly accurate\n",
    "\n",
    "Without GPU acceleration, this model cannot realistically run in real-time.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "- Incredibly accurate face detector\n",
    "- Small model size (under 1MB)\n",
    "- Expertly implemented and documented\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "- Requires an additional library (dlib) be installed\n",
    "- Code is more verbose — end-user must take care to convert and trim bounding box coordinates if using OpenCV\n",
    "- Cannot run in real-time without GPU acceleration\n",
    "- Not out-of-the-box compatible for acceleration via OpenVINO, Movidius NCS, NVIDIA Jetson Nano, or Google Coral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of using get_frontal_face_detector() we use cnn_face_detection_model_v1() and add the model path\n",
    "\n",
    "#Initialize the detector\n",
    "detector = dlib.cnn_face_detection_model_v1('./mmod_human_face_detector.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read, resize and recolor the image\n",
    "image = cv2.imread('./images/concert.jpg')\n",
    "image = imutils.resize(image, width=600)\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform face detection. This takes some time (at least compared to dlibs HOG+)\n",
    "rects = detector(rgb, 1 ) # 1 is the number of times to upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain the boxes coordinates from the face detection\n",
    "boxes = [convert_and_trim_bb(image, r.rect) for r in rects]\n",
    "\n",
    "#Draw the bb on the image\n",
    "for (x, y, w, h) in boxes:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gpu-dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da695c087d6368c9b262a08c2ebf368542a47f83b2881693eefdf5ebab9d0ecb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
