{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.9.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from imutils.video import VideoStream\n",
    "import imutils\n",
    "import mediapipe as mp\n",
    "import cv2 \n",
    "import pyshine as py \n",
    "import argparse\n",
    "import threading\n",
    "import time\n",
    "import pygame\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/juan/Downloads/escuchame.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFrame = None\n",
    "lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://quebuennombre:1234@192.168.45.71:8080/video'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastime = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.set_num_channels(8)\n",
    "insults = pygame.mixer.Sound(path)\n",
    "voice = pygame.mixer.Channel(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = VideoStream(url).start()\n",
    "time.sleep(2.0)\n",
    "lastime = dt.datetime.now()\n",
    "current = dt.datetime.now()\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.8, min_tracking_confidence=0.8) as pose:\n",
    "    \n",
    "    while True:\n",
    "        frame = cap.read()\n",
    "        image = imutils.resize(frame, 440)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "            # mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "            # mp_drawing.DrawingSpec(color= (245, 66, 230), thickness = 2, circle_radius=4))\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        faces = face_detector.detectMultiScale(image, 1.3, 5)\n",
    "        \n",
    "        if len(faces)> 0:\n",
    "\n",
    "            if landmarks[mp_pose.PoseLandmark.RIGHT_EYE].y >= 0.36 and landmarks[mp_pose.PoseLandmark.RIGHT_EYE].z < -2 and landmarks[mp_pose.PoseLandmark.LEFT_EYE].y >= 0.36:\n",
    "            # or\\\n",
    "            # landmarks[mp_pose.PoseLandmark.MOUTH_LEFT].y >= 0.50 or landmarks[mp_pose.PoseLandmark.MOUTH_RIGHT].y >= 0.50 or\\\n",
    "            # landmarks[mp_pose.PoseLandmark.NOSE].y >= 0.44:\n",
    "\n",
    "                if voice.get_busy() == False:\n",
    "                    if (current - lastime).seconds > 1:\n",
    "                        lastime = dt.datetime.now()\n",
    "                        voice.play(insults)\n",
    "\n",
    "\n",
    "                current = dt.datetime.now()\n",
    "\n",
    "            else:\n",
    "                voice.stop()\n",
    "\n",
    "        cv2.imshow(\"Mediapie feed\", image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            voice.stop()\n",
    "            break\n",
    "\n",
    "    #cap.stream.release() \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gpu-dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da695c087d6368c9b262a08c2ebf368542a47f83b2881693eefdf5ebab9d0ecb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
