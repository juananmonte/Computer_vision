{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Torch\n",
    "import torch\n",
    "from torch.nn import Module, Conv2d, Linear, MaxPool2d, ReLU, LogSoftmax\n",
    "from torch import flatten\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import KMNIST\n",
    "from sklearn.metrics import classification_report\n",
    "from torch import nn\n",
    "#---Others\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before everything, define de device to use: GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a CNN with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the class. the class helps in the process of initilalizing variables and uso those viarable to make operations on inputs in a certain order\n",
    "class LeNet(Module):\n",
    "    def __init__(self, numChannels, classes):\n",
    "        super(LeNet, self).__init__() #call parent constructor\n",
    "\n",
    "        #1 set: Convolution-Relu-Max\n",
    "        self.conv1 = Conv2d(in_channels= numChannels, out_channels= 20, kernel_size= (5,5))\n",
    "        self.relu1 = ReLU()\n",
    "        self.maxpool1 = MaxPool2d(kernel_size= (2,2), stride= (2,2))\n",
    "\n",
    "        #2 set: Convolution-Relu-Max\n",
    "        self.conv2 = Conv2d(in_channels=20, out_channels=50, kernel_size=(5,5))\n",
    "        self.relu2 = ReLU()\n",
    "        self.maxpool2 = MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "\n",
    "        #3 set: Fully Connected layer - Relu\n",
    "        self.fc1 = Linear(in_features=800, out_features=500)\n",
    "        self.relu3 = ReLU()\n",
    "\n",
    "        #4 set: Fully connected - softmax classifier\n",
    "        self.fc2 = Linear(in_features=500,out_features=classes)\n",
    "        self.logSoftmax = LogSoftmax(dim=1)\n",
    "    \n",
    "#---Define the steps of the NN\n",
    "    def forward(self, x):\n",
    "        #pass the input x through all the variables\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        output = self.logSoftmax(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = KMNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "testData = KMNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "#Get the validation dataset\n",
    "num_train_s = int(len(trainData)*0.75)\n",
    "num_val_s = int(len(trainData)*0.25)\n",
    "(trainData, valData) = random_split(trainData, [num_train_s, num_val_s],generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the pipeline using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader = DataLoader(trainData,shuffle=True, batch_size=64)\n",
    "valDataLoader = DataLoader(valData, shuffle=True, batch_size=64)\n",
    "testDataLoader = DataLoader(testData, batch_size=64) #Remember no shuffle on test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate steps per epoch\n",
    "trainSteps = len(trainDataLoader.dataset)//64\n",
    "valSteps = len(valDataLoader.dataset)//64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model and components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet(numChannels=1, classes=len(trainData.dataset.classes)).to(device)\n",
    "opt = Adam(model.parameters(), lr=1e-3)\n",
    "lossFn = nn.NLLLoss()\n",
    "\n",
    "#Get dictinary to store all trainig history\n",
    "H = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of LeNet(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (logSoftmax): LogSoftmax(dim=1)\n",
       ")>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the train and test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 1/10\n",
      "Train loss: 0.058191, Train accuracy: 0.9817\n",
      "Val loss: 0.083894, Val accuracy: 0.9735\n",
      "\n",
      "[INFO] EPOCH: 2/10\n",
      "Train loss: 0.035911, Train accuracy: 0.9894\n",
      "Val loss: 0.081237, Val accuracy: 0.9779\n",
      "\n",
      "[INFO] EPOCH: 3/10\n",
      "Train loss: 0.029287, Train accuracy: 0.9909\n",
      "Val loss: 0.086470, Val accuracy: 0.9759\n",
      "\n",
      "[INFO] EPOCH: 4/10\n",
      "Train loss: 0.023115, Train accuracy: 0.9925\n",
      "Val loss: 0.076216, Val accuracy: 0.9799\n",
      "\n",
      "[INFO] EPOCH: 5/10\n",
      "Train loss: 0.014633, Train accuracy: 0.9953\n",
      "Val loss: 0.075994, Val accuracy: 0.9812\n",
      "\n",
      "[INFO] EPOCH: 6/10\n",
      "Train loss: 0.014411, Train accuracy: 0.9954\n",
      "Val loss: 0.086828, Val accuracy: 0.9800\n",
      "\n",
      "[INFO] EPOCH: 7/10\n",
      "Train loss: 0.012144, Train accuracy: 0.9961\n",
      "Val loss: 0.105381, Val accuracy: 0.9766\n",
      "\n",
      "[INFO] EPOCH: 8/10\n",
      "Train loss: 0.010482, Train accuracy: 0.9964\n",
      "Val loss: 0.079974, Val accuracy: 0.9829\n",
      "\n",
      "[INFO] EPOCH: 9/10\n",
      "Train loss: 0.008616, Train accuracy: 0.9973\n",
      "Val loss: 0.078090, Val accuracy: 0.9833\n",
      "\n",
      "[INFO] EPOCH: 10/10\n",
      "Train loss: 0.004563, Train accuracy: 0.9986\n",
      "Val loss: 0.113566, Val accuracy: 0.9791\n",
      "\n",
      "[INFO] total time taken to train the model: 135.49s\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "for e in range(0, 10):\n",
    "    model.train() #Put the model on train mode\n",
    "\n",
    "    #Initializing the total training and validation\n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "\n",
    "    trainCorrect = 0\n",
    "    valCorrect = 0\n",
    "\n",
    "    for (x, y) in trainDataLoader:\n",
    "        (x,y) = (x.to(device), y.to(device))\n",
    "\n",
    "        #Do forward pass and calculate training loss\n",
    "        pred = model(x)\n",
    "        loss = lossFn(pred, y)\n",
    "\n",
    "        #define the 3 most important steps\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        #Add the train loss and accuracy\n",
    "        totalTrainLoss += loss\n",
    "        trainCorrect += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "\n",
    "        #Switch off autograd with .no-grad\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval() #and put the model on evaluation mode\n",
    "\n",
    "        for (x,y) in valDataLoader:\n",
    "            (x, y) = (x.to(device), y.to(device))\n",
    "            pred = model(x)\n",
    "            totalValLoss += lossFn(pred, y)\n",
    "            valCorrect += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "\n",
    "    #calculate the training and val loss average\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgValLoss = totalValLoss / valSteps\n",
    "\n",
    "    #calculate accuracy\n",
    "\n",
    "    trainCorrect = trainCorrect/len(trainDataLoader.dataset)\n",
    "    valCorrect = valCorrect/len(valDataLoader.dataset)\n",
    "\n",
    "    #Update training history\n",
    "    H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy()) #due to the backward pass\n",
    "    H[\"train_acc\"].append(trainCorrect)\n",
    "    H[\"val_loss\"].append(avgValLoss.cpu().detach().numpy()) #due to the backward pass\n",
    "    H[\"val_acc\"].append(trainCorrect)\n",
    "\n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(e + 1, 10))\n",
    "    print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(avgTrainLoss, trainCorrect))\n",
    "    print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(avgValLoss, valCorrect))\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           o       0.96      0.94      0.95      1000\n",
      "          ki       0.91      0.93      0.92      1000\n",
      "          su       0.89      0.94      0.92      1000\n",
      "         tsu       0.95      0.97      0.96      1000\n",
      "          na       0.93      0.93      0.93      1000\n",
      "          ha       0.97      0.93      0.95      1000\n",
      "          ma       0.95      0.97      0.96      1000\n",
      "          ya       0.98      0.83      0.90      1000\n",
      "          re       0.96      0.93      0.95      1000\n",
      "          wo       0.86      0.98      0.92      1000\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    #Store predictions\n",
    "    preds = []\n",
    "\n",
    "    for (x, y) in testDataLoader:\n",
    "        x = x.to(device) #don't forget to pass it to GPU/CUDA\n",
    "\n",
    "        #make predictions\n",
    "        pred = model(x)\n",
    "        preds.extend(pred.argmax(axis=1).cpu().numpy()) #\n",
    "\n",
    "        #Classification report\n",
    "print(classification_report(testData.targets.cpu().numpy(), np.array(preds), target_names=testData.classes)) #remember to put everything as a numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gpu-dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da695c087d6368c9b262a08c2ebf368542a47f83b2881693eefdf5ebab9d0ecb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
