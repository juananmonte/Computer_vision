{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195f129f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:17.513519Z",
     "start_time": "2021-08-10T11:16:16.765740Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import numpy as n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6bc7ef9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:19.367663Z",
     "start_time": "2021-08-10T11:16:17.516204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "datapath = 'C:/Users/juana/Desktop/Data Science/pytorch'\n",
    "cifar10 = datasets.CIFAR10(datapath, train = True, download = True)\n",
    "cifar10_val = datasets.CIFAR10(datapath, train = False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f2828b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:19.383393Z",
     "start_time": "2021-08-10T11:16:19.370661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a65582a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:19.399522Z",
     "start_time": "2021-08-10T11:16:19.386388Z"
    }
   },
   "outputs": [],
   "source": [
    "#Pytorch transforms the image to a PIL object\n",
    "img, lab = cifar10[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73bf9fce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:19.639243Z",
     "start_time": "2021-08-10T11:16:19.401521Z"
    }
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4852/3461510382.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wut'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#plt.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow('wut', img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53046c0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:19.656037Z",
     "start_time": "2021-08-10T11:16:19.641771Z"
    }
   },
   "outputs": [],
   "source": [
    "## Transforms makes the images (and numpy arrays) into tensors witht the function \"ToTensor\"\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_t = to_tensor(img)\n",
    "img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666590a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:21.499671Z",
     "start_time": "2021-08-10T11:16:19.659077Z"
    }
   },
   "outputs": [],
   "source": [
    "#we can even set this funtion from the moment que download the dataset\n",
    "tensor_cifar10 = datasets.CIFAR10(datapath, download = True, train = True, transform = transforms.ToTensor())\n",
    "tensor_cifar10_val = datasets.CIFAR10(datapath, download = True, train = False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c063b40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:21.512507Z",
     "start_time": "2021-08-10T11:16:21.501877Z"
    }
   },
   "outputs": [],
   "source": [
    "#How can we visualize the data if now is a tensor?\n",
    "img_t, lab = tensor_cifar10[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b820e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:21.763311Z",
     "start_time": "2021-08-10T11:16:21.516921Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_t.permute(1,2,0)) #Changes the order of the axes from  C × H × W   to    H × W × C\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904fae4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:39.070082Z",
     "start_time": "2021-08-10T11:16:21.766734Z"
    }
   },
   "outputs": [],
   "source": [
    "#Normalizzing the data\n",
    "\n",
    "#--------Steps:\n",
    "\n",
    "#---- 1) Let’s stack all the tensors returned by the dataset along an extra dimension:\n",
    "\n",
    "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim= 3)\n",
    "imgs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da49e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:42.517198Z",
     "start_time": "2021-08-10T11:16:39.071130Z"
    }
   },
   "outputs": [],
   "source": [
    "#-------2) Now we can easily compute the mean per channel\n",
    "\n",
    "#Recall that view(3, -1) keeps the three channels and  merges all the remaining dimensions into one, figuring  out the appropriate size. \n",
    "#Here our 3 × 32 × 32 image is transformed into a 3 × 1,024 vector, and then the mean  is taken over the 1,024 elements of each channel.\n",
    "\n",
    "#mean\n",
    "print(imgs.view(3,-1).mean(dim=1))\n",
    "\n",
    "#std\n",
    "print(imgs.view(3,-1).std(dim=1))\n",
    "\n",
    "# put the values from the two operations into the Normalizae function from transforms\n",
    "transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "\n",
    "# and concatenate it after the ToTensor transform\n",
    "\n",
    "transf_cifar10 = datasets.CIFAR10(datapath, train = True, download = True, \n",
    "                                  transform  = transforms.Compose([transforms.ToTensor(),\n",
    "                                               transforms.Normalize((0.4914, 0.4822, 0.4465),(0.247, 0.2435, 0.2616))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc6360",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:42.709387Z",
     "start_time": "2021-08-10T11:16:42.520198Z"
    }
   },
   "outputs": [],
   "source": [
    "img_n, _ = transf_cifar10[99]\n",
    "plt.imshow(img_n.permute(1,2,0)) #no olvidar el permute\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270efec",
   "metadata": {},
   "source": [
    "# Distinguishing birds from airplanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168df803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:59.862454Z",
     "start_time": "2021-08-10T11:16:42.711578Z"
    }
   },
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "\n",
    "cifar2 = [(img, label_map[label]) \n",
    "          for img, label in tensor_cifar10\n",
    "          if label in [0, 2]]\n",
    "\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in tensor_cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab91ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:59.904723Z",
     "start_time": "2021-08-10T11:16:59.867551Z"
    }
   },
   "outputs": [],
   "source": [
    "n_out = 2\n",
    "\n",
    "#create a normal linear model\n",
    "model = nn.Sequential(nn.Linear(3072, 512,), nn.Tanh(),nn.Linear(512, n_out,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45012b9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:59.919734Z",
     "start_time": "2021-08-10T11:16:59.908572Z"
    }
   },
   "outputs": [],
   "source": [
    "#Use a activation functoin Softmax\n",
    "\n",
    "softmax = nn.Softmax(dim = 1) #-----------> nn.Softmax requires us to specify the dimension along which the softmax function is applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4bf746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:16:59.963690Z",
     "start_time": "2021-08-10T11:16:59.921767Z"
    }
   },
   "outputs": [],
   "source": [
    "#putting all together\n",
    "\n",
    "model = nn.Sequential(nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, 2), nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87f54d",
   "metadata": {},
   "source": [
    "### We can actually try running the model before even training it. Let’s do it, just to see what comes out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe297f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:17:00.356186Z",
     "start_time": "2021-08-10T11:16:59.968848Z"
    }
   },
   "outputs": [],
   "source": [
    "#let's getan image\n",
    "\n",
    "img, _ = tensor_cifar10[0]\n",
    "\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544230a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:17:00.381824Z",
     "start_time": "2021-08-10T11:17:00.365862Z"
    }
   },
   "outputs": [],
   "source": [
    "# In order to call the model, we need to make the input have the right dimensions. \n",
    "# We recall that our model expects 3,072 features in the input, and that nn works with data organized into batches along the zeroth dimension. So we need to\n",
    "#turn our 3 × 32 × 32 image into a 1D tensor and then add an extra dimension\n",
    "\n",
    "img_batch = img.view(-1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c095d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:17:00.427316Z",
     "start_time": "2021-08-10T11:17:00.392278Z"
    }
   },
   "outputs": [],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ce0ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:17:00.458938Z",
     "start_time": "2021-08-10T11:17:00.434839Z"
    }
   },
   "outputs": [],
   "source": [
    "#see the argmax. the index thas the max probability\n",
    "_, index = torch.max(out, dim=1)\n",
    "index #it says the image is a plane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee635a6b",
   "metadata": {},
   "source": [
    "### Time to get training. As in the previous two chapters, we need a loss to minimize during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa045b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:20:37.113864Z",
     "start_time": "2021-08-10T11:17:00.464520Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(3072, 512),nn.Tanh(),nn.Linear(512, 2),nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss() #to evalueate the results\n",
    "\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar2:\n",
    "        out = model(img.view(-1).unsqueeze(0))#convert to 1D array\n",
    "        loss = loss_fn(out, torch.tensor([label])) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d69b3",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897df48e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:30:06.017992Z",
     "start_time": "2021-08-10T11:29:47.405348Z"
    }
   },
   "outputs": [],
   "source": [
    "#  DataLoader constructor takes a Dataset object as input, along with batch_size and a shuffle Boolean that indicates whether\n",
    "# the data needs to be shuffled at the beginning of each epoch. Is used as an hyperparameter for batchsizes and shuffle\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size = 64, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 2),\n",
    "    nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss() # bien nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader: #we just change it here <-----------\n",
    "        batch_size = imgs.shape[0]\n",
    "        out = model(imgs.view(batch_size, -1)) #no need to convert the batches to 1D\n",
    "        loss = loss_fn(out, labels) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss))) #Due to the shuffling, this now prints the loss for a random batch—clearly something we\n",
    "                                                        #want to improve in chapter 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db06b29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:41:38.465600Z",
     "start_time": "2021-08-10T11:41:38.288160Z"
    }
   },
   "outputs": [],
   "source": [
    "#we can compute the accuracy of our model on the validation set\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size= 64, shuffle = False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]#get the batch size\n",
    "        outputs = model(imgs.view(batch_size, -1))#pass the model through the batches\n",
    "        _, predicted = torch.max(outputs, dim=1)#predict the max value of the prediction made by the model\n",
    "        total += labels.shape[0]#get the labels shape\n",
    "        correct += int((predicted == labels).sum()) #transform the predicted result (is a float) and see if it matches the label number. if so, add it\n",
    "        print(\"Accuracy: %f\", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb66f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T11:50:06.499242Z",
     "start_time": "2021-08-10T11:50:06.489989Z"
    }
   },
   "outputs": [],
   "source": [
    "#calculate how many parameters does the model have\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n",
    "sum(numel_list), numel_list #105 million parameters\n",
    "\n",
    "#howdid we get that, remember a linear layer computes y = weight * x + bias parameters, so y = 512*3072+512. y needs to length 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdc7c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808d84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670dd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
