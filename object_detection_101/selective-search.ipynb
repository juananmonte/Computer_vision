{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selective Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selective Search, first introduced by Uijlings et al. in their 2012 paper,  is a critical piece of computer vision, deep learning, and object detection research.\n",
    "\n",
    "In their work, Uijlings et al. demonstrated:\n",
    "\n",
    "1. How images can be **over-segmented to automatically identify locations in an image that could contain an object**\n",
    "\n",
    "2. That Selective Search is **far more computationally efficient** than exhaustively computing image pyramids and sliding windows (and without loss of accuracy)\n",
    "\n",
    "3. Selective Search **can be swapped in for any object detection framework** that utilizes image pyramids and sliding windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selective Search works by over-segmenting an image using a superpixel algorithm\n",
    "\n",
    "\n",
    "Selective Search merges superpixels in a hierarchical fashion based on five key similarity measures:\n",
    "\n",
    "> **1. Color similarity:** \n",
    "\n",
    "Computing a 25-bin histogram for each channel of an image, concatenating them together, and obtaining a final descriptor that is 25×3=75-d. Color similarity of any two regions is measured by the histogram intersection distance.\n",
    "\n",
    "> **2. Texture similarity:** \n",
    "\n",
    "Selective Search extracts Gaussian derivatives at 8 orientations per channel (assuming a 3-channel image). These orientations are used to compute a 10-bin histogram per channel, generating a final texture descriptor that is 8x10x=240-d. **To compute texture similarity between any two regions, histogram intersection is once again used.**\n",
    "\n",
    "> **3. Size similarity:**\n",
    "\n",
    "The size similarity metric that Selective Search uses **prefers that smaller regions be grouped earlier rather than later.** Anyone who has used Hierarchical Agglomerative Clustering (HAC) algorithms before knows that HACs are prone to clusters reaching a critical mass and then combining everything that they touch. By enforcing smaller regions to merge earlier, we can help prevent a large number of clusters from swallowing up all smaller regions.\n",
    "\n",
    "> **4. Shape similarity/compatibility:** \n",
    "\n",
    "The idea behind shape similarity is that they should be compatible with each other. Two regions are considered “compatible” if they “fit” into each other (thereby filling gaps in our regional proposal generation). Furthermore, shapes that do not touch should not be merged.\n",
    "\n",
    "> **5. A final meta-similarity measure:** \n",
    "\n",
    "A final meta-similarity acts as a linear combination of the color similarity, texture similarity, size similarity, and shape similarity/compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the image and initiate selective search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('/media/juan/juan1/pyimage_univ/object_detect_201/opencv-selective-search/dog.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize cv2 selective search implementation\n",
    "#Need to have installed ONLY opencv-contrib-python. Two or more opencv packages together cause conflicts\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.setBaseImage(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of Selective search requires another step — choosing and setting the internal mode of operation.\n",
    "\n",
    "- The \"fast\" method: **switchToSelectiveSearchFast**\n",
    "\n",
    "- The \"quality\" method: **switchToSelectiveSearchQuality**\n",
    "\n",
    "Generally, the faster method will be suitable; however, depending on your application, you might want to sacrifice speed to achieve better quality results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.switchToSelectiveSearchFast()\n",
    "#ss.switchToSelectiveSearchQuality()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply selective search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.61 seconds\n",
      "length of region proposals by selective search: 1219\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rects = ss.process()\n",
    "end = time.time()\n",
    "print(\"Time taken: {:.2f} seconds\".format(end-start))\n",
    "print(\"length of region proposals by selective search: {}\".format(len(rects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize  the current subset of region proposals\n",
    "for i in range(0, len(rects), 100):\n",
    "    output = image.copy()\n",
    "    #loop over the subset of region proposals (12 in total)\n",
    "    for (x, y, w, h) in rects[i:i+100]:\n",
    "        #draw those regions proposals\n",
    "        #generate a random color for all the rectangles\n",
    "        color = [random.randint(0, 255) for j in range(0,3)]\n",
    "        #get the rectangles\n",
    "        cv2.rectangle(output, (x,y), (x+w, y+h), color, 2)\n",
    "    \n",
    "    cv2.imshow(\"Out\", output)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gpu-dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da695c087d6368c9b262a08c2ebf368542a47f83b2881693eefdf5ebab9d0ecb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
